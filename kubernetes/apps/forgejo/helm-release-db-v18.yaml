---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &name forgejo-postgres-v18
  namespace: flux-system
spec:
  interval: 30m
  chart:
    spec:
      chart: raw
      version: v0.3.2
      sourceRef:
        kind: HelmRepository
        name: dysnix-charts
        namespace: flux-system
      interval: 30m
  targetNamespace: &namespace forgejo
  install:
    createNamespace: true
    remediation:
      retries: 10
  upgrade:
    remediation:
      retries: 10
  dependsOn:
    - name: cloudnative-pg
      namespace: flux-system
  values:
    resources:
      - apiVersion: postgresql.cnpg.io/v1
        kind: Cluster
        metadata:
          name: *name
          namespace: *namespace
        spec:
          # using only 1 replica: very difficult to drain the node where postgres is running
          # using more than 1 replica: write amplification issues when leveraging replicated storage (e.g. ceph)
          instances: 2
          imageName: ghcr.io/cloudnative-pg/postgresql:18.0
          primaryUpdateStrategy: unsupervised
          storage:
            size: 5Gi
            storageClass: "${STORAGE_READWRITEONCE}"
          managed:
            roles:
              - name: forgejo
                login: true
                passwordSecret:
                  name: forgejo-basic-auth
          superuserSecret:
            name: *name
          bootstrap:
            # use this to start a new cluster
            initdb:
              database: forgejo
              owner: forgejo
              secret:
                name: forgejo-basic-auth
            # use this to recover a net-new cluster from a backup
            #recovery:
            #  source: *name
            #  database: forgejo
            #  owner: forgejo
            # # use this to 'migrate' from an existing cnpg cluster (e.g. "forgejo-postgres-v17") to the new cluster
            #initdb:
            #  database: forgejo
            #  owner: forgejo
            #  import:
            #    type: microservice
            #    databases:
            #      - forgejo
            #    source:
            #      externalCluster: forgejo-postgres-v17
          monitoring:
            enablePodMonitor: "${MONITORING_PROMETHEUS}"
          resources:
            requests:
              cpu: "200m"
              memory: "128Mi"
            limits:
              memory: "1Gi"
          backup:
            retentionPolicy: 7d
            barmanObjectStore:
              wal:
                compression: bzip2
                maxParallel: 4
              destinationPath: s3://postgresql-${CLUSTER_NAME}
              endpointURL: "${SECRET_S3_URL}"
              serverName: *name
              s3Credentials:
                accessKeyId:
                  name: *name
                  key: s3-access-key
                secretAccessKey:
                  name: *name
                  key: s3-secret-key
          externalClusters:
            # this represents the s3 backup to restore from. Must be same version.
            - name: *name
              barmanObjectStore:
                wal:
                  compression: bzip2
                  maxParallel: 8
                destinationPath: s3://postgresql-${CLUSTER_NAME}
                serverName: *name
                endpointURL: "${SECRET_S3_URL}"
                s3Credentials:
                  accessKeyId:
                    name: *name
                    key: s3-access-key
                  secretAccessKey:
                    name: *name
                    key: s3-secret-key
            # # this represents an existing cnpg cluster to migrate from (e.g. upgrading from postgres v17 to postgres v188)
            #- name: forgejo-postgres-v17
            #  connectionParameters:
            #    host: forgejo-postgres-v17.forgejo.svc.cluster.local
            #    user: forgejo
            #    dbname: forgejo
            #    sslmode: require
            #  password:
            #    name: forgejo-basic-auth
            #    key: password
      - apiVersion: postgresql.cnpg.io/v1
        kind: ScheduledBackup
        metadata:
          name: *name
          namespace: *namespace
        spec:
          schedule: "0 37 01 * * *"
          immediate: true
          backupOwnerReference: self
          cluster:
            name: *name
