---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &name authentik-postgres-v18
  namespace: flux-system
spec:
  interval: 30m
  chart:
    spec:
      chart: raw
      version: v0.3.2
      sourceRef:
        kind: HelmRepository
        name: dysnix-charts
        namespace: flux-system
      interval: 30m
  targetNamespace: &namespace authentik
  install:
    createNamespace: true
    remediation:
      retries: 10
  upgrade:
    remediation:
      retries: 10
  dependsOn:
    - name: cloudnative-pg
      namespace: flux-system
  values:
    resources:
      - apiVersion: postgresql.cnpg.io/v1
        kind: Cluster
        metadata:
          name: *name
          namespace: *namespace
        spec:
          # using only 1 replica: very difficult to drain the node where postgres is running
          # using more than 1 replica: write amplification issues when leveraging replicated storage (e.g. ceph)
          instances: 2
          imageName: ghcr.io/cloudnative-pg/postgresql:18.1
          primaryUpdateStrategy: unsupervised
          storage:
            size: 10Gi
            storageClass: "${STORAGE_READWRITEONCE}"
          managed:
            roles:
              - name: authentik
                login: true
                passwordSecret:
                  name: authentik-basic-auth
          superuserSecret:
            name: *name
          bootstrap:
            # use this to start a new cluster
            initdb:
              database: authentik
              owner: authentik
              secret:
                name: authentik-basic-auth
            # use this to recover a net-new cluster from a backup
            #recovery:
            #  source: *name
            #  database: authentik
            #  owner: authentik
            # # use this to 'migrate' from an existing cnpg cluster (e.g. "authentik-postgres-v17") to the new cluster
            #initdb:
            #  database: authentik
            #  owner: authentik
            #  import:
            #    type: microservice
            #    databases:
            #      - authentik
            #    source:
            #      externalCluster: authentik-postgres-v17
          monitoring:
            enablePodMonitor: "${MONITORING_PROMETHEUS}"
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              memory: "1Gi"
          backup:
            retentionPolicy: 7d
            barmanObjectStore:
              wal:
                compression: bzip2
                maxParallel: 4
              destinationPath: s3://postgresql-${CLUSTER_NAME}
              endpointURL: "${SECRET_S3_URL}"
              serverName: *name
              s3Credentials:
                accessKeyId:
                  name: *name
                  key: s3-access-key
                secretAccessKey:
                  name: *name
                  key: s3-secret-key
          externalClusters:
            # this represents the s3 backup to restore from. Must be same version.
            - name: *name
              barmanObjectStore:
                wal:
                  compression: bzip2
                  maxParallel: 8
                destinationPath: s3://postgresql-${CLUSTER_NAME}
                serverName: *name
                endpointURL: "${SECRET_S3_URL}"
                s3Credentials:
                  accessKeyId:
                    name: *name
                    key: s3-access-key
                  secretAccessKey:
                    name: *name
                    key: s3-secret-key
            # # this represents an existing cnpg cluster to migrate from (e.g. upgrading from postgres v17 to postgres v18)
            #- name: authentik-postgres-v17
            #  connectionParameters:
            #    host: authentik-postgres-v17.authentik.svc.cluster.local
            #    user: authentik
            #    dbname: authentik
            #    sslmode: require
            #  password:
            #    name: authentik-basic-auth
            #    key: password
      - apiVersion: postgresql.cnpg.io/v1
        kind: ScheduledBackup
        metadata:
          name: *name
          namespace: *namespace
        spec:
          schedule: "0 37 01 * * *"
          immediate: true
          backupOwnerReference: self
          cluster:
            name: *name
      - apiVersion: networking.k8s.io/v1
        kind: NetworkPolicy
        metadata:
          name: *name
          namespace: *namespace
        spec:
          podSelector:
            matchLabels:
              cnpg.io/cluster: *name
          policyTypes:
            - Ingress
            - Egress
          ingress:
            - from:
                - podSelector:
                    matchLabels:
                      cnpg.io/cluster: *name
                - podSelector:
                    matchLabels:
                      app.kubernetes.io/controller: authentik
                      app.kubernetes.io/instance: authentik-authentik
                      app.kubernetes.io/name: authentik-authentik
              ports:
                - port: 5432
                  protocol: TCP
            - from:
                - namespaceSelector:
                    matchLabels:
                      kubernetes.io/metadata.name: cloudnative-pg
                  podSelector:
                    matchLabels:
                      app.kubernetes.io/name: cloudnative-pg
                - podSelector:
                    matchLabels:
                      cnpg.io/cluster: *name
              ports:
                - port: 8000
                  protocol: TCP
            - from:
                - namespaceSelector:
                    matchLabels:
                      kubernetes.io/metadata.name: monitoring
                  podSelector:
                    matchLabels:
                      app.kubernetes.io/name: prometheus
              ports:
                - port: 9187
          egress:
            - to:
                - podSelector:
                    matchLabels:
                      cnpg.io/cluster: *name
              ports:
                - port: 5432
                  protocol: TCP
                - port: 8000
                  protocol: TCP
            - to:
                - namespaceSelector:
                    matchLabels:
                      kubernetes.io/metadata.name: kube-system
                  podSelector:
                    matchLabels:
                      k8s-app: kube-dns
              ports:
                - port: 53
                  protocol: UDP
            - to: # S3-Backup
              - ipBlock:
                  cidr: 10.0.1.75/32
              ports:
                - port: 9000
                  protocol: TCP
      - apiVersion: cilium.io/v2
        kind: CiliumNetworkPolicy
        metadata:
          name: *name
          namespace: *namespace
        spec:
          endpointSelector:
            matchLabels:
              cnpg.io/cluster: *name
          egress:
            - toEntities:
              - kube-apiserver