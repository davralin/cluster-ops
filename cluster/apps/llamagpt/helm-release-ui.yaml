---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: llamagpt-ui
  namespace: llamagpt
spec:
  interval: 5m
  chart:
    spec:
      chart: app-template
      version: 1.5.1
      sourceRef:
        kind: HelmRepository
        name: bjw-s-charts
        namespace: flux-system
      interval: 5m
  targetNamespace: llamagpt
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  values:
    fullnameOverride: llamagpt-ui
    image:
      repository: ghcr.io/getumbrel/llama-gpt-ui
      tag: latest
    service:
      main:
        ports:
          http:
            port: 3000
    ingress:
      main:
        enabled: true
        annotations:
          haproxy.org/whitelist: "${HAPROXY_WHITELIST}"
          haproxy.org/response-set-header: |
            Strict-Transport-Security "max-age=31536000"
            X-Frame-Options "DENY"
            X-Content-Type-Options "nosniff"
            Referrer-Policy "no-referrer-when-downgrade"
        hosts:
          - host: "llamagpt.${SECRET_DEFAULT_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - secretName: "${SECRET_DEFAULT_DOMAIN_CERT}"
    env:
      MODEL: "/models/llama-2-7b-chat.bin"
      OPENAI_API_HOST: "http://llama-gpt-api:8000"
      OPENAI_API_KEY: "sk-XXXXXXXXXXXXXXXXXXXX"
      WAIT_HOSTS: "llama-gpt-api:8000"
      WAIT_TIMEOUT: "600"
    resources:
      requests:
        memory: 100Mi
      limits:
        memory: 200Mi
